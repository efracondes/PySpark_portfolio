{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the Occurences of the Words in a Text\n",
    "\n",
    "In this notebook we use PySpark to count the occurrences of the words in a text. The text we used for this excercise can be found at ../datasets/text.txt. Although this text was randomly generated and doesn't possess any kind of meaning, the reader must consider that our main goal in this excercise is to show a use case of the .flatMap() transformation.\n",
    "\n",
    "First we call the some libraries and tell the computer that we are going to run the script on our local system.First we call the some libraries and tell the computer that we are going to run the script on our local system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster('local').setAppName('words_counter')\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our data and print the first line of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coconut apple orange hazelnut\nblueberry pumpkin pepper carrot\nwatercress tomato radish almond\npeas pickle pumpkin rice\nspinach potato turnip wheat apricot\n"
    }
   ],
   "source": [
    "raw_text = sc.textFile('../datasets/text.txt')\n",
    "\n",
    "for row in raw_text.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our text consists only of fruits' names.\n",
    "\n",
    "In the following cell we use the .flatMap() tranformation in order to split the strings into words. We've used the .map tranformation in similar tasks, the main difference here is that using the .flatMap tranformation each word will be stored in the new RDD as independent values, in contrast with .map that returns a list per line whose elements consist of the line's words. We'll print some values of the new RDD to make this more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coconut\napple\norange\nhazelnut\nblueberry\npumpkin\npepper\ncarrot\nwatercress\ntomato\n"
    }
   ],
   "source": [
    "words = raw_text.flatMap(lambda string: string.split())\n",
    "\n",
    "for word in words.take(10):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can count the occurences of each word and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Word: coconut, Occurences: 7\nWord: apple, Occurences: 1\nWord: orange, Occurences: 3\nWord: hazelnut, Occurences: 3\nWord: blueberry, Occurences: 7\nWord: pumpkin, Occurences: 4\nWord: pepper, Occurences: 2\nWord: carrot, Occurences: 2\nWord: watercress, Occurences: 2\nWord: tomato, Occurences: 4\nWord: radish, Occurences: 4\nWord: almond, Occurences: 1\nWord: peas, Occurences: 5\nWord: pickle, Occurences: 3\nWord: rice, Occurences: 5\nWord: spinach, Occurences: 4\nWord: potato, Occurences: 8\nWord: turnip, Occurences: 5\nWord: wheat, Occurences: 7\nWord: apricot, Occurences: 7\nWord: grape, Occurences: 4\nWord: lemon, Occurences: 6\nWord: melon, Occurences: 4\nWord: peach, Occurences: 6\nWord: pineapple, Occurences: 4\nWord: raspberry, Occurences: 4\nWord: watermelon, Occurences: 6\nWord: artichoke, Occurences: 9\nWord: beans, Occurences: 5\nWord: brussels, Occurences: 5\nWord: cauliflower, Occurences: 5\nWord: courgette, Occurences: 11\nWord: garlic, Occurences: 7\nWord: lettuce, Occurences: 7\nWord: mango, Occurences: 2\nWord: tangerine, Occurences: 2\nWord: plum, Occurences: 2\nWord: lime, Occurences: 4\nWord: cabbage, Occurences: 4\nWord: onion, Occurences: 4\nWord: squash, Occurences: 3\nWord: rye, Occurences: 4\nWord: leek, Occurences: 1\nWord: eggplant, Occurences: 1\nWord: celery, Occurences: 3\nWord: beetroot, Occurences: 2\nWord: asparagus, Occurences: 1\nWord: aubergine, Occurences: 1\nWord: broccoli, Occurences: 4\nWord: corn, Occurences: 1\nWord: cucumber, Occurences: 1\nWord: lentils, Occurences: 1\nWord: mushroom, Occurences: 2\nWord: cherry, Occurences: 2\nWord: banana, Occurences: 2\n"
    }
   ],
   "source": [
    "word_occurrences = words.countByValue()\n",
    "\n",
    "for word, occurrences in word_occurrences.items():\n",
    "    print('Word: ' + str(word) + ', Occurences: ' + str(occurrences))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "spark",
   "display_name": "spark"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}