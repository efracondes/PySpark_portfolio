{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the Occurences of the Words in a Text\n",
    "\n",
    "In this notebook, we use PySpark to count the occurrences of the words in a text. The text used for this exercise can be found at ../datasets/text.txt. Although this text was randomly generated and doesn't possess any meaning, the reader must consider that our main goal in this exercise is to show a use case of the .flatMap() transformation, not to give any kind of interpretation to the results.\n",
    "\n",
    "First we call the some libraries and tell the computer that we are going to run the script on our local system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster('local').setAppName('words_counter')\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our data and print the first five lines of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coconut apple orange hazelnut\n",
      "blueberry pumpkin pepper carrot\n",
      "watercress tomato radish almond\n",
      "peas pickle pumpkin rice\n",
      "spinach potato turnip wheat apricot\n"
     ]
    }
   ],
   "source": [
    "raw_text = sc.textFile('../datasets/text.txt')\n",
    "\n",
    "for row in raw_text.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our text consists only of fruits and vegetables' names.\n",
    "\n",
    "In the next cell, we use the .flatMap() transformation to split the strings into words. We've used the .map transformation in similar tasks. The main difference here is that using the .flatMap transformation each word will be stored in the new RDD as independent values, in contrast with .map that returns a list per line whose elements consist of the line's words. We'll print some values of the new RDD to make this more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coconut\n",
      "apple\n",
      "orange\n",
      "hazelnut\n",
      "blueberry\n",
      "pumpkin\n",
      "pepper\n",
      "carrot\n",
      "watercress\n",
      "tomato\n"
     ]
    }
   ],
   "source": [
    "words = raw_text.flatMap(lambda string: string.split())\n",
    "\n",
    "for word in words.take(10):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can count the occurrences of each word and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: coconut, Occurences: 7\n",
      "Word: apple, Occurences: 1\n",
      "Word: orange, Occurences: 3\n",
      "Word: hazelnut, Occurences: 3\n",
      "Word: blueberry, Occurences: 7\n",
      "Word: pumpkin, Occurences: 4\n",
      "Word: pepper, Occurences: 2\n",
      "Word: carrot, Occurences: 2\n",
      "Word: watercress, Occurences: 2\n",
      "Word: tomato, Occurences: 4\n",
      "Word: radish, Occurences: 4\n",
      "Word: almond, Occurences: 1\n",
      "Word: peas, Occurences: 5\n",
      "Word: pickle, Occurences: 3\n",
      "Word: rice, Occurences: 5\n",
      "Word: spinach, Occurences: 4\n",
      "Word: potato, Occurences: 8\n",
      "Word: turnip, Occurences: 5\n",
      "Word: wheat, Occurences: 7\n",
      "Word: apricot, Occurences: 7\n",
      "Word: grape, Occurences: 4\n",
      "Word: lemon, Occurences: 6\n",
      "Word: melon, Occurences: 4\n",
      "Word: peach, Occurences: 6\n",
      "Word: pineapple, Occurences: 4\n",
      "Word: raspberry, Occurences: 4\n",
      "Word: watermelon, Occurences: 6\n",
      "Word: artichoke, Occurences: 9\n",
      "Word: beans, Occurences: 5\n",
      "Word: brussels, Occurences: 5\n",
      "Word: cauliflower, Occurences: 5\n",
      "Word: courgette, Occurences: 11\n",
      "Word: garlic, Occurences: 7\n",
      "Word: lettuce, Occurences: 7\n",
      "Word: mango, Occurences: 2\n",
      "Word: tangerine, Occurences: 2\n",
      "Word: plum, Occurences: 2\n",
      "Word: lime, Occurences: 4\n",
      "Word: cabbage, Occurences: 4\n",
      "Word: onion, Occurences: 4\n",
      "Word: squash, Occurences: 3\n",
      "Word: rye, Occurences: 4\n",
      "Word: leek, Occurences: 1\n",
      "Word: eggplant, Occurences: 1\n",
      "Word: celery, Occurences: 3\n",
      "Word: beetroot, Occurences: 2\n",
      "Word: asparagus, Occurences: 1\n",
      "Word: aubergine, Occurences: 1\n",
      "Word: broccoli, Occurences: 4\n",
      "Word: corn, Occurences: 1\n",
      "Word: cucumber, Occurences: 1\n",
      "Word: lentils, Occurences: 1\n",
      "Word: mushroom, Occurences: 2\n",
      "Word: cherry, Occurences: 2\n",
      "Word: banana, Occurences: 2\n"
     ]
    }
   ],
   "source": [
    "word_occurrences = words.countByValue()\n",
    "\n",
    "for word, occurrences in word_occurrences.items():\n",
    "    print('Word: ' + str(word) + ', Occurences: ' + str(occurrences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
